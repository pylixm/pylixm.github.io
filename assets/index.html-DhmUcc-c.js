import{_ as e,c as t,a as r,o as i}from"./app-DdES4ywf.js";const o="/imgs/kafka/kafka_architecture.png",n="/imgs/kafka/consumer-groups.png",p={};function s(l,a){return i(),t("div",null,[...a[0]||(a[0]=[r('<h2 id="历史" tabindex="-1"><a class="header-anchor" href="#历史"><span>历史</span></a></h2><p>消息代理，狭义的讲它是一种按照某专递协议进行消息传递的架构模式。常用来解决系统之间的耦合、异步任务调用和瞬时流量的应对问题。随着互联网行业的发展，大数据、分布式架构的兴起，消息代理的使用越来越多，高吞吐、实时性的要求越来越高。</p><p>Kafka 就是在这样的背景下诞生的。在2010年，Linkedin公司需要将大量的数据集成到现有架构中做处理，当时现有的传消息代理中间件无法满足他们的需求，高吞吐、低延迟且安全容错率高。他们决定自己开发一套消息代理系统，就此Kafka 诞生。次年，他们将它开源到了github，因为它高吞吐、低延迟的特点被纳入apache孵化器项目，2012年成为apache顶级项目。</p><p>随着Kafka的发展，它已经不局限于消息代理。现在已发展为一个分布式流处理平台，具有以下三种特性：</p><ul><li>可以让你发布和订阅流式的记录。这一方面与消息队列或者企业消息系统类似。</li><li>可以储存流式的记录，并且有较好的容错性。</li><li>可以在流式记录产生时就进行处理。</li></ul><h2 id="kafka的中常用概念" tabindex="-1"><a class="header-anchor" href="#kafka的中常用概念"><span>kafka的中常用概念</span></a></h2><p>在我们使用Kafka之前，先来了解下期中的一些概念。Kafka的<a href="http://kafka.apache.org/intro" target="_blank" rel="noopener noreferrer">官方文档</a>已经描述的非常详细，下边是一些总结：</p><p><strong>常识类</strong></p><ul><li>Kafka作为一个集群，运行在一台或者多台服务器上.</li><li>Kafka 通过 topic 对存储的流数据进行分类。</li><li>每条记录中包含一个key，一个value和一个timestamp（时间戳）。</li><li>kafka中的消息是无状态的，不会随着消费而消失，只会根据保留策略来释放。</li></ul><p><strong>组件类</strong></p><p><img src="'+o+'" alt=""></p><ul><li>主题（topic）：一个topic可以认为是一类消息。</li><li>分区（partition）：每个topic可以分为多个分区，存储到集群的不同节点，同时可以设置副本的个数来达到可容错的效果。分区突破主机单文件大小的限制，并且为并行数据处理提供了条件。</li><li>复制备份（replication）：kafka将每个partition数据复制到多个server上，任何一个partition有一个leader和多个follower(可以没有)，备份的个数可以通过broker配置文件来设定。</li><li>生产者（producers）：将消息写入到kakfa服务端的称之为生产者。Producers将消息发布到指定的Topic中,同时Producer也能决定将此消息归属于哪个partition</li><li>代理（Broker）：已发布的消息保存在一组服务节点中，每个节点称之为一个broker，所有的broker组成一个kafka集群。</li><li>消费者（customers）：将消息从kakfa服务端取出使用的称之为消费者。如果所有的consumer都具有相同的group,这种情况和队列模式很像，消息将会在consumers之间负载均衡；如果所有的consumer都具有不同的group,那这就是&quot;发布-订阅&quot;，消息将会广播给所有的消费者。</li><li>zookeeper： 用来存储机器的配置信息。</li></ul><h1 id="kafka-搭建" tabindex="-1"><a class="header-anchor" href="#kafka-搭建"><span>Kafka 搭建</span></a></h1><p>Kafka集群的搭建非常简单，可直接参考<a href="http://kafka.apache.org/quickstart" target="_blank" rel="noopener noreferrer">官方文档</a>。</p><h2 id="启动时注意" tabindex="-1"><a class="header-anchor" href="#启动时注意"><span>启动时注意</span></a></h2><p>在Kafka启动时，<code>kafka-server-start.sh</code> 提供了daemon模式，可通过添加参数<code>-daemon</code> 实现。</p><p>Kafka启动后，我们需要监控kafka的运行情况，许多开源的监控的系统需要Kafka打开 <code>JMX</code>功能，我们直接指定JMX的端口即可，<code>kafka-server-start.sh</code>中做了处理，它会自动添加其他jvm需要的参数。</p><p>总结上边，我们的完整启动命令如下：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-"><span class="line"><span>JMX_PORT=9988 ./bin/kafka-server-start.sh -daemon config/server.properties</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h2 id="几个重要的配置" tabindex="-1"><a class="header-anchor" href="#几个重要的配置"><span>几个重要的配置</span></a></h2><ul><li><code>offsets.topic.replication.factor</code> topic 分区的副本数，默认为1，即没有副本。当有broker宕机的时候，topic信息不全，导致集群不可用。建议设置参数值大于1.</li><li><code>log.retention.hours</code> 日志文件清理，默认为168。建议根据自己磁盘和数据量合理设置，以免因磁盘满造成宕机不可用。</li></ul><h1 id="使用问题和优化" tabindex="-1"><a class="header-anchor" href="#使用问题和优化"><span>使用问题和优化</span></a></h1><h2 id="针对kafka的管理监控问题" tabindex="-1"><a class="header-anchor" href="#针对kafka的管理监控问题"><span>针对kafka的管理监控问题</span></a></h2><p>对于kafka管理及监控，这里推荐两款开源工具 <a href="https://github.com/yahoo/CMAK" target="_blank" rel="noopener noreferrer">Kafka Manager</a> 和 <a href="https://github.com/smartloli/kafka-eagle" target="_blank" rel="noopener noreferrer">Kafka Eagle</a>。</p><p><strong>Kafka Manager</strong></p><p>该工具是目前最后欢迎的Kafka机器管理工具，是有雅虎开源的。提供了简单的web页面，可实现多集群的主题管理和消费者等状态的查看。</p><p><strong>Kafka Eagle</strong></p><p>该工具是国内同行开发的，支持对Kafka的简单管理和报警，可以看作者这篇剖析来进一步了解：<a href="https://www.cnblogs.com/smartloli/p/9371904.html" target="_blank" rel="noopener noreferrer">Kafka监控系统Kafka Eagle剖析</a></p><h2 id="利用customer-group-实现消费者的高可用" tabindex="-1"><a class="header-anchor" href="#利用customer-group-实现消费者的高可用"><span>利用Customer Group 实现消费者的高可用</span></a></h2><p>根据消费者组(Customer Group)的特性，不同的消费者组可以订阅同样的topic数据。Topic 会将数据广播到每个订阅的消费者组，在消费者组内，一个topic的分区对应一个消费者来消费，每个topic的分区只能被一个消费者消费。</p><p>在一个消费者组中，当有消费者宕机时，该消费者消费的分区会重新平衡到其他消费者上继续消费，从消费者组整体来看，仍然是完整可用的。这样以组作为一个消费集群来看，便是高可用的了。</p><p><img src="'+n+'" alt=""></p><h1 id="扩展阅读" tabindex="-1"><a class="header-anchor" href="#扩展阅读"><span>扩展阅读</span></a></h1><ul><li><a href="https://blog.csdn.net/GitChat/article/details/80991660" target="_blank" rel="noopener noreferrer">系统架构的演变</a></li><li><a href="https://stackshare.io/stackups/activemq-vs-kafka-vs-rabbitmq" target="_blank" rel="noopener noreferrer">kafka与其他mq对比</a></li><li><a href="https://tanzu.vmware.com/content/blog/understanding-when-to-use-rabbitmq-or-apache-kafka" target="_blank" rel="noopener noreferrer">了解合适使用RabbitMQ和Apache Kafka</a></li></ul>',34)])])}const k=e(p,[["render",s]]),h=JSON.parse('{"path":"/pages/37cc9e/","title":"Kafka 使用总结","lang":"zh-CN","frontmatter":{"title":"Kafka 使用总结","tags":["DevOps","kafka"],"permalink":"/pages/37cc9e/","createTime":"2023/09/08 17:36:02","description":"历史 消息代理，狭义的讲它是一种按照某专递协议进行消息传递的架构模式。常用来解决系统之间的耦合、异步任务调用和瞬时流量的应对问题。随着互联网行业的发展，大数据、分布式架构的兴起，消息代理的使用越来越多，高吞吐、实时性的要求越来越高。 Kafka 就是在这样的背景下诞生的。在2010年，Linkedin公司需要将大量的数据集成到现有架构中做处理，当时现有...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Kafka 使用总结\\",\\"image\\":[\\"https://pylixm.top/imgs/kafka/kafka_architecture.png\\",\\"https://pylixm.top/imgs/kafka/consumer-groups.png\\"],\\"dateModified\\":\\"2025-09-30T08:57:49.000Z\\",\\"author\\":[]}"],["meta",{"property":"og:url","content":"https://pylixm.top/pages/37cc9e/"}],["meta",{"property":"og:site_name","content":"底层逻辑"}],["meta",{"property":"og:title","content":"Kafka 使用总结"}],["meta",{"property":"og:description","content":"历史 消息代理，狭义的讲它是一种按照某专递协议进行消息传递的架构模式。常用来解决系统之间的耦合、异步任务调用和瞬时流量的应对问题。随着互联网行业的发展，大数据、分布式架构的兴起，消息代理的使用越来越多，高吞吐、实时性的要求越来越高。 Kafka 就是在这样的背景下诞生的。在2010年，Linkedin公司需要将大量的数据集成到现有架构中做处理，当时现有..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://pylixm.top/imgs/kafka/kafka_architecture.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-09-30T08:57:49.000Z"}],["meta",{"property":"article:tag","content":"kafka"}],["meta",{"property":"article:tag","content":"DevOps"}],["meta",{"property":"article:modified_time","content":"2025-09-30T08:57:49.000Z"}]]},"readingTime":{"minutes":4.86,"words":1457},"git":{"createdTime":1759222669000,"updatedTime":1759222669000,"contributors":[{"name":"pylixm","username":"pylixm","email":"pyli.xm@gmail.com","commits":1,"avatar":"https://avatars.githubusercontent.com/pylixm?v=4","url":"https://github.com/pylixm"}]},"autoDesc":true,"filePathRelative":"03.中间件/03.kafka/01.kafka.md","headers":[],"categoryList":[{"id":"affec3","sort":3,"name":"中间件"},{"id":"2942cf","sort":3,"name":"kafka"}]}');export{k as comp,h as data};
