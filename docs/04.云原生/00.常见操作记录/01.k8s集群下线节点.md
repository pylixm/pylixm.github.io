---
title: k8s 集群维护和下线节点
tags:
  - k8s

permalink: /pages/4e940d/
createTime: 2023/09/08 17:36:02
---


## 1、不参与调度 cordon 

命令如下：
```bash
# 不参与调度 , 
kubectl cordon <nodename>
# 重新参与调度， 可回复节点状态
kubectl uncordon <nodename>
```

影响：
- 节点变成 SchedulingDisabled
- 节点不参与pod调度，新pod不会被调度到该节点，老pod不收影响，正常提供服务


## 2、驱逐节点 drain 

```bash
# 驱逐节点
kubectl drain --ignore-daemonsets --delete-emptydir-data <nodename>
# 回复节点
kubectl uncordon node_name
```

参数：
- `--ignore-daemonsets` drain 默认不会删除 daemonsets 控制器控制的pod, 添加该参数则会清理。
- `--delete-emptydir-data` 当使用有本地卷时会有该warning，添加该参数明确该事项，本地数据会被清空。

影响：
- 驱逐node上的pod，会在其他节点重新创建
- 将节点调为** SchedulingDisabled**


## 3、删除下线节点 delete

```bash
# 删除该节点
kubectl delete nodes <nodename>
```

影响：
- 1、驱逐node上的pod，其他节点重新创建
- 2、从master节点删除该node，master对其不可见，失去对其控制，master不可对其恢复


恢复调度：
- 1.进入node节点，重启kubelet
- 2.基于node的自注册功能，节点重新恢复使用：systemctl restart kubelet


## 4、一个完整的维护或下线步骤

```bash
# 1、查看集群节点信息
kubectl get nodes -o wide
# 查看特定节点下的pod
kubectl get pods --all-namespaces -o wide --field-selector spec.nodeName=<nodename>


# 2、不参与调度 或 驱逐节点pod
kubectl cordon <nodename>
# 驱逐下线节点上的pod
kubectl drain --ignore-daemonsets --delete-emptydir-data <nodename>

# 3、做维护 或删除节点之后 维护
# 删除该节点
kubectl delete nodes <nodename>

# 4、反驱逐回复节点，或重启kubelet 重新申请加入集群
kubectl uncordon <nodename>

```
注意：
- delete是一个比较粗暴的命令，它会将被删node上的pod直接驱逐，由其他node创建（针对replicaset），然后将被删节点从master管理范围内移除，master对其失去管理控制，若想重新获取该node的控制管理，需要在该node节点重启kubelet）
- 为了确保drain驱逐pod的时候，容器应用服务不中断，必须满足：
  - 要驱逐的pod副本数量必须大于1
  - 要配置"反亲和策略"，确保被驱逐的pod被调度到不同的Node节点上
  - deployment采用滚动更新，设置maxUnavailable为0，maxSurge为1